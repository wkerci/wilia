import streamlit as st
from torchvision.models import resnet50, ResNet50_Weights
from torchvision import transforms
from PIL import Image
import torch
from openai import OpenAI
import os

# ğŸ›ï¸ ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(page_title="ResNet50 + Assistente IA", layout="centered")
st.title("ğŸ–¼ï¸ Classificador com ResNet50 + ğŸ’¬ Chat com IA")

# ğŸ” Chave da API
openai_key = os.getenv("OPENAI_API_KEY")  # Configure esta variÃ¡vel no ambiente do Streamlit Cloud

if not openai_key:
    st.warning("âš ï¸ API Key da OpenAI nÃ£o encontrada. Adicione a variÃ¡vel 'OPENAI_API_KEY' no ambiente.")
else:
    client = OpenAI(api_key=openai_key)

# âš™ï¸ Carregamento do modelo ResNet50
modelo = resnet50(weights=ResNet50_Weights.DEFAULT)
modelo.eval()

# ğŸ”§ TransformaÃ§Ãµes da imagem
transformacao = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.485, 0.456, 0.406],
        std=[0.229, 0.224, 0.225]
    )
])

# ğŸ“ Upload da imagem
arquivo = st.file_uploader("Selecione uma imagem para classificar...", type=["jpg", "jpeg", "png"])

if arquivo:
    try:
        imagem = Image.open(arquivo).convert("RGB")
        st.image(imagem, caption="Imagem enviada", use_column_width=True)

        entrada = transformacao(imagem).unsqueeze(0)

        with torch.no_grad():
            saida = modelo(entrada)
            indice = saida.argmax().item()

        rotulos = ResNet50_Weights.DEFAULT.meta["categories"]
        classe = rotulos[indice]

        st.success(f"ğŸ§  Classe identificada: **{classe}**")

    except Exception as e:
        st.error(f"âŒ Erro ao processar a imagem: {e}")
else:
    st.info("ğŸ‘† Envie uma imagem para iniciar a classificaÃ§Ã£o.")

# ğŸ’¬ Campo de Perguntas
st.markdown("---")
st.header("Pergunte algo ao assistente IA")

pergunta = st.text_input("Digite sua pergunta:")

if pergunta and openai_key:
    with st.spinner("Pensando..."):
        try:
            resposta = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[{"role": "user", "content": pergunta}]
            )
            texto = resposta.choices[0].message.content
            st.info(texto)

        except Exception as e:
            st.error(f"âŒ Erro na resposta do chatbot: {e}")
